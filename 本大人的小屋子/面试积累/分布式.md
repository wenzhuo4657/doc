# dubbo

## 什么是dubbo

是一款高性能、轻量级的开源 WEB 和 RPC 框架。
Dubbo 提供了六大核心能力
面向接口代理的高性能 RPC 调用。
智能容错和负载均衡。
服务自动注册和发现。
高度可扩展能力。
运行期流量调度。
可视化的服务治理与运维。

## dubbo支持的协议
Hessian(默认)
dubbo
FastJSON2
Protobuf


### hessian协议的优点

1，跨语言
2，效率相比于文本格式的json和xml更紧凑

## 为什么要使用dubbo
使用dubbo的场景一定是分布式架构，在该架构下程序面临着调用外部服务的任务，而dubbo正是基于这一点提供了许多易用的功能。例如：
负载均衡：当一个服务被多端部署时，系统应当调用哪一个。
服务调用链路生成： 服务提供方之间的依赖关系复杂，难以找到调用链路，例如，当程序需要调用服务a时，该服务a又作为服务提供方的同时也作为服务的使用方。


## 服务之间的调用为啥不直接用 HTTP 而用 RPC？
[有了 HTTP 协议，为什么还要有 RPC ？ | JavaGuide](https://javaguide.cn/distributed-system/rpc/http_rpc.html#http-%E5%92%8C-rpc-%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB)

http1.1对比rpc
传输数据：http1.1使用文本，rpc使用二进制
链接池：http1.1虽然使用长链接，但长时间不使用依旧会关闭，而rpc会专门建立链接池管理
服务发现，http协议中，要么使用域名，要么使用ip，但终究是直接调用到服务本身，而rpc则会有专门的服务组件去完成这个部分，也就是服务发现，同时也带来了更加多样化的功能，例如负载均衡、服务调用链路等。



## Dubbo注册中心扮演了什么角色？注册中心挂了可以继续通信吗？
注册中心用于帮助生产者注册服务地址、服务者调用获取地址。当注册中心挂了的时候，对于dubbo来说只是无法及时的获取最新的服务地址列表，对于本地程序来说dubbo会缓存一部分服务列表，这部分列表会根据情况来判断是否可以通信。



## dubbo负载均衡策略

[负载均衡 | Apache Dubbo](https://cn.dubbo.apache.org/zh-cn/overview/what/core-features/load-balance/)

![](img/Pasted%20image%2020250122144919.png)

## Dubbo的spi

dubbo中的spi相比jd提供了更为强大的功能，
1，按需加载，即可以通过键值指定，而非每次加载都需要将所有的类都实例化。
2，自适应装配扩展方法执行时加载，这位不同方法提供了更加灵活的配置方式。
3，由于内部是通过包装类加载数据，因此对于加载失败等错误会自行处理。




# 网关


## 什么是网关？
一般情况下，网关可以为我们提供请求转发、安全认证（身份/权限认证）、流量控制、负载均衡、降级熔断、日志、监控、参数校验、协议转换等功能。
网关主要做了两件事情：请求转发 + 请求过滤，是服务调用层面的服务。





# 分布式锁

## 为什么需要分布式锁？
分布式锁主要是实现共享资源的互斥访问，如果不适用分布式锁，很可能导致并发访问的问题，操作的原子性、有序性、可见性问题。


## ## [分布式锁应该具备哪些条件？](https://javaguide.cn/distributed-system/distributed-lock.html#%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%BA%94%E8%AF%A5%E5%85%B7%E5%A4%87%E5%93%AA%E4%BA%9B%E6%9D%A1%E4%BB%B6)

互斥：任意一个时刻，锁只能被一个线程持有。
高可用：当某个获取锁的服务出现问题时（从锁的角度上，一般表现为无法释放分布式锁），可以切换到另一个锁。（**普遍实现为超时机制**，或者是zookeeper的临时顺序节点：会随着会话的消失而销毁）
可重入：一个节点获取锁之后，还可以再获取锁。

## 为什么要给锁设置一个过期时间

该问题实际上是高可用的实现问题，由于分布式场景下，一个锁会对应不同的系统服务，这意味着高容错，而高容错又提出了一个场景，即如果锁服务a出现问题，需要保证锁服务b的正常运行。
具体来说，则是a获取了锁，但是服务运行失败，导致锁没有正常释放，此时需要保证锁服务b可以正常运行。
最普遍的实现方式即锁的过期时间设置。

并且由于这一点，导致分布式锁大多都具有过期时间，然后这也带来了另一个问题，如何使锁再线程执行时一直持有锁?即应该如何再服务执行时给锁续期？

、

## redssion
### 看门狗机制
[blog.51cto.com/u\_16213688/7540380](https://blog.51cto.com/u_16213688/7540380)


关键方法scheduleExpirationRenewal，未设置有效期的锁会调用到这个方法。
```
protected void scheduleExpirationRenewal(long threadId) {  
ExpirationEntry entry = new ExpirationEntry();  
ExpirationEntry oldEntry = EXPIRATION_RENEWAL_MAP.putIfAbsent(getEntryName(), entry);  
if (oldEntry != null) {  
oldEntry.addThreadId(threadId); //该位置已经关联有锁，直接重入
} else {  
entry.addThreadId(threadId);  
try {  
renewExpiration();  //第一次获取锁，设置续约任务
} finally {  
if (Thread.currentThread().isInterrupted()) {  
cancelExpirationRenewal(threadId);  
}  
}  
}  
}
```


renewExpiration()设置延迟任务自动续期，延迟时间为
`internalLockLeaseTime / 3, TimeUnit.MILLISECONDS`,也就是自动续期时间的1/3，


```
private void renewExpiration() {  
ExpirationEntry ee = EXPIRATION_RENEWAL_MAP.get(getEntryName());  
if (ee == null) {  
return;  
}  
  
Timeout task = getServiceManager().newTimeout(new TimerTask() {  
@Override  
public void run(Timeout timeout) throws Exception {  
ExpirationEntry ent = EXPIRATION_RENEWAL_MAP.get(getEntryName());  
if (ent == null) {  
return;  
}  
Long threadId = ent.getFirstThreadId();  
if (threadId == null) {  
return;  
}  
  
CompletionStage<Boolean> future = renewExpirationAsync(threadId);  
future.whenComplete((res, e) -> {  
if (e != null) {  
log.error("Can't update lock {} expiration", getRawName(), e);  
EXPIRATION_RENEWAL_MAP.remove(getEntryName());  
return;  
}  
  
if (res) {  
// reschedule itself  
renewExpiration();  
} else {  
cancelExpirationRenewal(null);  
}  
});  
}  
}, internalLockLeaseTime / 3, TimeUnit.MILLISECONDS);  
  
ee.setTimeout(task);  
}
```



### 可重入机制

核心方法`scheduleExpirationRenewal`中存在可重入方法`oldEntry.addThreadId(threadId)`
```

private final Map<Long, Integer> threadIds = new LinkedHashMap<>();
public synchronized void addThreadId(long threadId) {  
threadIds.compute(threadId, (t, counter) -> {  
counter = Optional.ofNullable(counter).orElse(0);  
counter++;  
return counter;  
});  
}
```



## zookeeper


### 为什么使用临时顺序节点实现分布式锁

这是基于临时顺序节点的特性决定的，临时节点的生命周期是与 客户端会话（session） 绑定的，会话消失则节点消失 。并且，临时节点只能做叶子节点 ，不能创建子节点。
而这一点正好满足分布式锁的高可用性。


### 为什么zookeeper会对前一个节点设置监听器，

这是因为zookeeper一般会设置序列号最小的节点获取锁，所以前一个节点删除后，就应当轮到当前节点。




# rocketmq

## RocketMQ 如何实现分布式事务？

mq分布式事务指可以根据本地事务的完成状况来决定事务消息是否被消费，而rocketmq提供了两种机制，一个是在执行事务后手动提交，另外一个是通过事务回查机制，就是通过本地事务的唯一地段或者说如果事务执行成功就一个会有某个结果，根据这个结果是否存在来判断事务消息是否被提交。

## 消息重试机制
[消息发送重试和流控机制 | RocketMQ](https://rocketmq.apache.org/zh/docs/featureBehavior/05sendretrypolicy)
[消息队列RocketMQ版的消息重试机制是什么\_云消息队列 RocketMQ 版(RocketMQ)-阿里云帮助中心](https://help.aliyun.com/zh/apsaramq-for-rocketmq/cloud-message-queue-rocketmq-4-x-series/developer-reference/message-retry)

客户端消息发送请求调用失败或请求超时

网络异常造成连接失败或请求超时。

服务端节点处于重启或下线等状态造成连接失败。

服务端运行慢造成请求超时。

服务端返回失败错误码

系统逻辑错误：因运行逻辑不正确造成的错误。

系统流控错误：因容量超限造成的流控错误。

在官网给出的几种重试的可能原因，可以很清楚的看到因为超时而引起的重试并不少，我们需要注意这一点，这意味着在消费时我们需要保证消息的幂等。


对于消费失败且重试后依然失败的消息，云消息队列 RocketMQ 版不会立丢弃，而是将消息转发至指定的队列中，即死信队列，这些消息即为死信消息。当消费失败的原因排查并解决后，您可以重发这些死信消息，让消费者重新消费；若您暂时无法处理这些死信消息，为避免到期后死信消息被删除，您也可以先将死信消息导出进行保存。


## rocketmq架构

nameServer:broker节点的注册中心,为生产者和消费者提供broker的路由信息。
broker:真正与生产者和消费者进行交互的实例。
生产者：向broker发送消息。
消费者：向broker消费消息。


## 如何解决消息堆积问题？
消息积压指mq中存储了过多的消息，这个现象是由于生产者生产过多或者消费者消费过慢产生的，总之是由于两边的进度不协调，可以直接通过限流降级生产者和增加消费者实例解决（如果是广播消费不行，该方式针对集群消费模式）。同时需要检查消费者是否出现消费错误导致消费过慢，或者出现死锁等原因导致线程卡死。


## 消息队列中生产者和消费者之间线程配比一般是多少
这个问题和具体的mq消费模式相关，对于rocketmq来说，4.0版本之前的负载均衡策略默认是队列颗粒度，这意味着消费者的最大消费效率和主题队列数量正相关，此外就是生产者的生产时间以及空闲时间，5.0之后才用消息颗粒度，此时消费速率和队列数量非绝对正相关，可以通过无限制的增加消费者实例来解决消息积压问题。
也就是说，对于生产者和消费者的线程配比，要考虑生产速率和消息的负载均衡，如果我们假定消费者和生产者的速率一样，可以在消息颗粒度情况下，配置设置为1:1.

## 如何保证消息不丢失

消息不丢失可分成两步骤，
1，生产者成功发送至broket节点
2，broket节点接收到消息一定将其持久化

第一点无论是同步发送还是异步发送，都会通过broker响应的ack来确认，所以可以认为这个阶段虽然可能失败，但多次尝试下一定会成功
而存储阶段，可以使用同步刷盘和异步刷盘，二者都可能在执行过程中宕机，但相对而言，同步刷盘的容错率较高，只是会损失一定的性能，必须要注意的是，即使是持久化成功也并不能说明该消息一定不会丢失，如果是在集群场景下，该broker节点意外下线，虽然最终可以找到，但是消息的消费流程可能会因此出错，对于这一点，我们设置可以等待 2 个以上的节点同步消息完成后再给 Producer 返回成功
# CDN

 静态资源：图片、视频、脚本文件等不会随着用户请求而变化的资源。
 动态资源：业务数据、个性化推荐等由后端程序动态生成返回的资源



# 分库分表

## 分库分表会带来什么问题

分布式id：数据库的自增id无法满足需求
join:分散表在不同数据库，会导致无法完成连接查询
事务操作：分布式事务需要额外的解决方案，（一般用Sharding-JDBC）


## 数据迁移

分为全量迁移和增量迁移，
全量迁移直接停机，然后写一个脚本将老库的数据都同步到新库中。
增量同步，一般是基于binlog日志，例如cacanl组件，但是一个额外的组件会增项大量成本。还可以使用双写，只是代码复杂度上升，对项目维护有很大负荷。


## 分库分表下ID全局唯一是如何做的？

uuid
雪花算法
数据库自增id(通过指定步长来保证全局唯一)
redis缓存一个id值，然后incr生成全局唯一
zookeeper顺序节点。

# redis集群问题

## 哨兵机制

### Sentinel有什么用？
Redis Sentinel 实现 Redis 集群高可用，只是在主从复制实现集群的基础下，多了一个 Sentinel 角色来帮助我们监控 Redis 节点的运行状态并自动实现故障转移。

当 master 节点出现故障的时候， Sentinel 会帮助我们实现故障转移，自动根据一定的规则选出一个 slave 升级为 master，确保整个 Redis 系统的可用性。整个过程完全自动，不需要人工介入。


### Sentinel 如何检测节点是否下线？
主观下线(SDOWN) ：sentinel 节点认为某个 Redis 节点已经下线了（主观下线），但还不是很确定，需要其他 sentinel 节点的投票。（某个节点的角度）
●
客观下线(ODOWN) ：法定数量（通常为过半）的 sentinel 节点认定某个 Redis 节点已经下线（客观下线），那它就算是真的下线了。（集群角度）


### Sentinel故障转移，

当 master 节点出现故障的时候， Sentinel 会帮助我们实现故障转移，它首先会根据Raft 算法选举中选举 leader节点，然后leader通过投票、优先级等规则判断出master节点，并更新这一配置到整个集群当中。
### redis解决脑裂问题

脑裂：由于网络等因素导致不同节点产生分区，然后由于故障转移推举出了多个主节点，而客户端并不能感知到这个事实，不同的写入最终导致数据不一致问题。


解决：合理的故障转移配置，例如实现时间，最小投票数等，但是都并没有实质性的从逻辑上避免脑裂问题。




