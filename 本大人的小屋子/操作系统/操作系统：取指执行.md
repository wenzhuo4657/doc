
# 操作系统的启动
## 引导扇区
*将代码从磁盘中读取到内存中，且注意内存地址是cpu通过地址总线向外连接的方式，并非是整块的存储条*


![image.png](http://obimage.wenzhuo4657.cn/20240809095940.png)

注意，这里更改cs：ip，也就是cpu执行的指向，

然后进入引导扇区bootsect.s中执行
![image.png](http://obimage.wenzhuo4657.cn/20240809100602.png)

bootsect.s又将代码映射到0x9000:0x0000处，然后使用jmpi段间转移，跳转到go标号。（也就是将cs:ip指向了引导代码中的某一程序）

这里有一个问题，为什么要这样频繁的移动代码？



![image.png](http://obimage.wenzhuo4657.cn/20240809101337.png)


注意int 0x13中断，该中断会将将setuo4个扇区移动到0x9000:0x200,也就是段内转移，这里需要提醒的是，前两次转移的字数都为256（512字节，这是该课程所讨论的系统的设定），也就是一个boot扇区。


![image.png](http://obimage.wenzhuo4657.cn/20240809102042.png)


call read_it继续向下执行，依旧是调用13号中断转移代码，，最后末尾处，jmpi 0,setupseg将段地址变为0x9020,意味着boot扇区执行完毕，将cpu控制权转移给了setup.s


## setup
*获取计算机各种信息形成一个表，便于操作计算机管理。*


扩展内存，通常将1m以后的内存称为扩展内存。


![image.png](http://obimage.wenzhuo4657.cn/20240809104636.png)



setup主要作用:
- 将system模块移动到0地址处
- 读取各种参数到内存中
- 进入保护模式/32位机模式，




保护模式：实际上就是改变寻址模式，在cpu中表现为对cs、ip的解释不一样，对于传统的地址加法器进行更改，使其从20位-》32位。

![image.png](http://obimage.wenzhuo4657.cn/20240809105707.png)



![image.png](http://obimage.wenzhuo4657.cn/20240809105816.png)


**保护模式下，cs表和中断表的解释将不同。**

*cs、和n并非是地址，而是在对应表中的索引位置。*

## system
## head：进入保护模式之后的初始化
system模块中的第一部分代码，
*对idt、gpt页表重新初始化，转到main函数*
![image.png](http://obimage.wenzhuo4657.cn/20240809114028.png)
![image.png](http://obimage.wenzhuo4657.cn/20240809114056.png)



![image.png](http://obimage.wenzhuo4657.cn/20240809114146.png)


# 操作系统的接口

![image.png](http://obimage.wenzhuo4657.cn/20240810104436.png)


## 内核段和用户段
在内存中，为了避免system区域被用户随意访问，在硬件层面进行了限制。
![image.png](http://obimage.wenzhuo4657.cn/20240810105625.png)

cpl（cs）：当前cs特权级
dpl：段描述符的一部分字段，存储在gpt或者ipt表中，并非是实际段地址后两位
rpl(ds)：段选择子（在操作系统启动中所建立的gpt、ipt表以及system内存区域，致使ds存储的并不是直接的段，而是查表的索引）的特权级别

只有当max(RPL, CPL) <= DPL时，访问才能成功.


通常情况下，系统函数（即内核提供的服务）的段描述符的 DPL 会设置为 0，这意味着这些函数只能被具有最高权限级别的代码访问，通常是内核态的代码。用户程序在用户态（CPL 3）下运行时，其 RPL 通常也是 3，这意味着用户程序本身只能访问那些 DPL 为 3 的段，即用户空间的段。


## 系统调用 (System Call)
定义：**系统调用** 是用户程序与操作系统内核之间的接口，用于请求内核服务


例如在x86中的中断指令int（int指令会将cs的cpl改成0，）

需要注意的是cpl的特权级别是硬件自动完成的，调用完成之后又会恢复，且这期间rpl并没有改变，（ *用户程序通过系统调用来访问内核函数时，硬件自动处理了特权级别的切换，使得用户程序可以在保持 RPL 为 3 的情况下请求内核服务。*）




*多进程图谱（和cpu、内存密不可分）和文件操作视图（和io设备、磁盘密不可分）是操作系统的两个重要概念*



# 多进程图谱


## cpu管理的最直观想法

在使用过程中，会出现阻塞性的指令（例如io等），空闲时间的出现会导致cpu利用率降低，此时就是去管理cpu，也就是处理cpu阻塞导致浪费时间的问题。

实际上，所谓cpu管理换种说法，就是尽可能的提高cpu的利用率，也就是处理可能导致浪费cpu执行时间的指令。



![](http://obimage.wenzhuo4657.cn/20240811193658.png)



提高cpu利用率的手段是在空闲时切换程序执行，但简单的修改cs：ip不会切换程序对应的信息，因此有了PCB、进程来辅助管理cpu。


## 多进程图像


现代计算机大多是多任务系统，通过快速地在不同进程之间切换CPU时间来实现的，给用户一种所有进程都在同时运行的错觉，这种技术称为**时间片轮转**或**上下文切换**，但实际上但实际上任何时刻在一个cpu核（现代cpu大多数是多核）中只有一个进程在执行。


![image.png](http://obimage.wenzhuo4657.cn/20240811201442.png)


### 线程调度
![](http://obimage.wenzhuo4657.cn/20240811202604.png)



![image.png](http://obimage.wenzhuo4657.cn/20240811202654.png)




![](http://obimage.wenzhuo4657.cn/20240811204008.png)







1，操作系统如何组织？根据pcb、状态形成队列放在不同位置
2，操作系统如何切换？调度选择下一个进程，并得到对应pcb的信息，然后对cpu中对应信息进行覆盖、修改，最后修改cs：ip进行执行。
3，多个进程交替执行所造成的影响如何解决？例如，多个进程的代码都在内存中执行，地址空间会互相写入，解决方法为地址空间分离。（地址空间分离保证了进程安全，但与之相对的影响是进程之间交互的代价提高）



### 用户级线程

同进程下的多个线程会共享资源（也就是内存空间，换句话说，其地址映射表不会进行切换），且由于共用地址空间，多线程可进行协同工作，与之相对造成的影响是线程不安全。


#### 线程隔离
核心方法：*yield()和threadcreate()*


![](http://obimage.wenzhuo4657.cn/20240813182833.png)



tcb:线程级别的变量，其存储的esp（tcb.esp）表示的跳转表的地址，
esp：cpu上的寄存器，表示当前线程的跳转表的地址。


*此外注意{}，其中}会触发ret指令弹栈。*



![[img/Pasted image 20240813183451.png]]

![[img/Pasted image 20240813184146.png]]



![[img/Pasted image 20240813184959.png]]


用户级线程一大特点是，tcb对内核不可见，换句话说，如果某个线程阻塞，操作系统无法知道进程内部线程的情况，也就无法形成调度，对于操作系统来说，只能该进程堵塞，切换到其他进程执行。
这种情况的问题是，进程可能会因为某个线程的堵塞导致整个进程堵塞。


### 内核线程

*内核线程的ThreadCreate是系统调用（核心线程的tcb在内核空间中创建），与用户级别线程的ThreadCreate不同*
![[img/Pasted image 20240813193441.png]]


![[img/Pasted image 20240813185119.png]]


注意：只有到内核中才能够分配资源，也就是将某个线程或者进程分配cpu核心，换言之，进行调度。
此地引申**并发并行**，如果是同个进程内多个用户级线程，其内部线程无法同时分配cpu核心，也就是说无法实现并行，但核心线程可以。


![[img/Pasted image 20240813185851.png]]





核心线程既可以访问内核态也可以访问用户态，因此对于核心线程来说，具有两个栈（用户栈和内核栈），例如，如果使用了int中断指令进入内核，核心线程就会切换为内核栈。



### 内核级线程的代码实现

#### 切换/中断五段论：
- 1，中断入口：建立用户栈和内核栈的关联，进入内核执行一段时间后，有例如磁盘读的事件，判断，时间片用完和阻塞都会触发schedule()
- 2，schedule()：调度方法
- 3，switch_to()：由于schedule()函数的执行，此时n已经为下一个tss的选择子，实际上的工作为，1，将原tss快照保存，2，tr（任务寄存器）指向新的选择子，并将其指向的tss加载进cpu中

   *tss内部的字段分为两类：1，所有寄存器的信息集，2，静态信息集（该区域为线程提供了一组私有的数据，包含esp线程执行序列的栈等）*
 ![[img/Pasted image 20240814182852.png]]
- 4，中断返回：把中断进入阶段中断处理函数压栈的寄存器弹栈  
- 5，用户栈切换：用iret指令把int指令压入的ss,esp,eflags,cs,eip弹栈


#### 系统调用_sys_fork

![[img/Pasted image 20240814190744.png]]

![[img/Pasted image 20240814190655.png]]

上述代码可知sys_fork创建的子进程和父进程共用同一用户栈，但是内核栈不同。

##### 如何区分子进程和父进程
此外需要注意如何区分父进程和子进程，下列三行汇编使用 `int 0x80` 指令来调用 `fork()` 这个c语言函数
![[img/Pasted image 20240814193125.png]]

`fork()` 系统调用返回后，返回值会被放在 `eax` 寄存器中。这条指令将 `eax` 寄存器中的返回值移动到 `res` 变量中，这样就可以在后续的代码中使用这个返回值。如果 `eax` 的值为0，则表示当前进程是子进程；如果 `eax` 的值大于0，则表示当前进程是父进程，并且 `eax` 中存储的是子进程的PID。

实际上表述含义是int 0x80内部会新建子进程之类的指令会修改eax寄存器的值，让其不等于1，标识这是一个子进程。



##### if(!fork){exec(cmd);}

fork()语句的返回值就是eax的值，该值可以帮助我们区分子进程和父进程，但是注意此时两个线程的用户栈是同一个，如果不加以设定就会完全相同，执行同样的代码。*因此需要exec（cmd）改变*

![[img/Pasted image 20240814194712.png]]



##### 示例

for的返回值：
- **在子进程中**：`fork()` 返回 0。
- **在父进程中**：`fork()` 返回子进程的进程标识符（PID），这是一个正整数。
- **失败时**：`fork()` 返回 -1，并且 `errno` 变量会被设置以表示错误原因。



![[img/Pasted image 20240814202450.png]]


*注意执行是主进程调用fork返回值为子进程的pid，这意味是两个if都无法进入，或者说在主进程中不会进入if中打印字母，由于子进程和父进程共用用户栈，也就是说执行的代码是相同的，对于第一个进程执行第一个循环一直打印a，第二个进程则一直打印b，由于主线程执行了wait，*


**子进程和父进程是两个独立的进程，每个进程都有自己的进程标识符，这意味着上述代码所创建的子进程的执行时机取决于系统调度，主进程对于子进程何时执行不做干涉。**




## cpu调度策略


*调度的核心目标：进程*
其衡量的指标有：
**尽快的结束任务：周转时间（从任务进入到任务结束，并非执行时间，需要加上等待的时间）短**
**用户操作尽快响应：响应时间快（从操作发生到响应）**
**吞吐量高：（完成任务量）：实际上就是两个指标的前提下，尽量减少损耗的时间**



指标之间的矛盾：
- 响应时间快->切换次数多->系统不能专注如完成任务->吞吐量降低
- 前台任务关注响应速度，例如鼠标点击等，后台任务专注周转时间，例如下载文件等
总结：响应速度和吞吐量有矛盾，周转时间和响应速度有矛盾。

此外还有些任务不需要cpu，例如io任务等。


| 常见调度方法 | des           |                   |
| ------ | ------------- | ----------------- |
| FCFS   | 不做调度，顺序执行     |                   |
| SPF    | （不可抢占）短作业优先执行 | 周转时间低             |
| SRTF   | （可抢占）短作业优先执行  |                   |
| RR     | 按照时间片轮转执行     | 保证了响应速度，且注意时间片大小。 |


然而在实际运行中，任务可划分为前台和后台任务，前台任务重视响应速度，适合轮转RR调度，后台任务重视周转时间，适合短作业优先SJS调度，因此可以将前后台任务分开调度，建立两个队列，*因此在实际运行中，调度问题被抽象化为如何调度两个队列的执行。*


###  schedule调度函数

![[img/Pasted image 20240816160725.png]]


counter：时间片
该函数使用counter表示优先级，且每执行一次该函数，io约束的阻塞进程（此处io约束表示为**非就绪状态**!TASK_RUNNING）的优先级会提高，也就是counter会变大，因此对于后台线程来说，近似了SJS调度，而前台程序处于就绪状态，时间片counter不被该函数改变。


## 进程同步和信号量



### 信号量的定义




![[img/Pasted image 20240816164833.png]]


单纯信号counter仅仅只能表示需要生产者，但并未给出明确的指示，例如：唤醒几个生产者，可能会有大量消费者同一时间消费，这是需要唤醒多个生产者，也可能只有一个生产者需要被唤醒。
*单纯的一个信号难以表达进程如何合作，所以引出了信号量来表达更丰富的信息。*




![[img/Pasted image 20240816170301.png]]


进程1命令为P,进程2命令为C，当P进程需要C进程时，sem--.当C进程需要P进程时sem++,注意此时，双方的合作在0时到达了平衡，解决了0、1表示信号量难以表达需要另一线程的程度的问题。

这种信号量实现了简单的进程合作同一件任务，复数任务的不需要调度，或者说调度不是信号量考虑的。


对于进程合作来说，何时停止等待？何时运行？是非常重要的两个问题，且由于进程内部还有线程，所以更进一步的说，停止多少，运行多少依旧是重要的问题，而信号量是非常好的解决手段，对于信号量来说，不必关心加减的具体含义，对值的解析是进程的任务。



**这只是信号量的一种表示，还有其他类似的表示**。





### 信号量的临界保护


#### 调度错误：竞争共享数据资源
![[img/Pasted image 20240819091732.png]]

两次执行由于系统调度问题，执行顺序出有上图的可能出现，问题的根本在于代码执行时，empty的值不准确，或者说，共享资源被不同进程同时使用，但没有加以约束。

![[img/Pasted image 20240819092608.png]]




进入临界区的Peterson算法
![[img/Pasted image 20240819095345.png]]




单独的令牌结构解决了互斥原则，即同一时间只能有一个进程进入临界区。
缺点：进入临界区可能出现阻塞，但是由于令牌系统调度无法让其他进程执行。
*且注意,令牌trun是由对方进程让出来的，也就是说当前进程第一次执行while时必定阻塞，至少触发两次系统调度后，只有一个进程能进入临时区域，并且在退出临时区时将令牌转移。*



单独登记簿结构解决了阻塞问题，即该变量的具体意义为当前临界区不会出现阻塞，就是就绪状态，又或者进程申请执行临时区（这里具体如何申请不必考虑，只需要理解当进程使用该变量区申请时就表明不会出现阻塞）。
缺点：对于就绪状态的处理会导致bug,只有对方进程的就绪状态处于假时才会执行，如果双发都处于就绪状态为真时，就会陷入无限等待。



两者结合使用：令牌结构解决了单独登记博的无限等待问题。

情况1：假设对方进程没有申请执行，这里大概率默认值为false，则直接进入临时区。
情况2：对方进程申请执行，由于将令牌让出去了，这里会进入while循环，由系统调度执行进程2，然后又一次将令牌让出去（*这里可能会有其他的执行循序，但排除了情况1的前提下，双方都进行了申请，此时由于严格轮换的trun令牌，双方循环经过至少2次的系统调度，最终只能进入一个。*）


**总的来说严格令牌轮换保证只能进入一个进程，但无法保证当前进程是否想要进入临时区（这里的想要进入，大概是阻塞之类的问题，具体实现此处不去考虑），此时使用登记簿表示当前进程的申请记录。**



#### 阻止调度

对于共享资源的多线程修改，实际上是系统调度切换进程执行的问题，假如我们可以在执行临时区时阻止系统调度，也就是中断等进入系统内核的指令的，也可以达到目的。


##### 单cpu：阻止中断

多进程在同一cpu核上轮换执行，可以使用下图代码实现。
![[img/Pasted image 20240819110906.png]]



其中cli（）可以阻止cpu查看intr寄存器（该寄存器的作用是cpu在执行机器代码会查看其中的值来判断是否发生中断切换）。


但是对于多cpu来说，不同进程在不同cpu核心上执行，该方法无效。




##### 多cpu（多核）:硬件原子指令法



### 信号量的具体实现


![[img/Pasted image 20240819151834.png]]


注意lock——buffer（）：磁盘读信号量的临界保护，执行完成代表磁盘读取完成。

bh->lock表示磁盘读信号量：1代表上锁，

当有进程读磁盘时，其他进程读相同区域时会阻塞在lock_buffer()函数中的while内部，调用sleep_on函数。

![[img/Pasted image 20240819152146.png]]


该队列的盲点在于current在何时入队？事实上，该函数甚至没给出current变量的创建，

![[img/Pasted image 20240819152329.png]]

但是我们可以根据信号量的定义得知，该task_struct为任务队列的定义，而current为当前进程的任务变量（**我们可以理解为current不需要创建，已经存在于队列中**），事实上在sleep_on函数的下一句将current的状态定义为休眠，并且调用schedule函数进行系统调度。


最终指向： current/* p  ->当前任务变量 ->tmp ->原阻塞队列


sleep_on函数是调用同一信号量时的保护操作，其p队列表示的是阻塞队列，且需要注意schedule()会进行系统调度，切换到另一进程的schedule代码处，这代表着系统调度之后，会立即执行if（tmp）{tmp->state=0}唤醒下一进程。

我们不去关心阻塞队列如何形成，而是一旦形成之后如何释放这些队列，在代码中给出的方式：假设某进程，然后系统调度到该进程，然后依次唤醒下一进程（这里需要注意，该阻塞队列内部均是以信号量bh->b_lock为锁的进程）。


问题是如何唤醒队首的进程，
![[img/Pasted image 20240819164337.png]]
![[img/Pasted image 20240819164257.png]]




假设进程1读磁盘，并且将在读磁盘时将bh->b_lock=，此时其他进程2、3、4..由于信号量进入循环并且调用sleep_on函数执行相同操作并且依次入队，此时进程2、3...进程全部阻塞，等待磁盘中断唤醒进程1，进程1被唤醒后，执行unlock_buffer()函数释放锁，并且唤醒队列首部的进程。（*如果上一进程没有读取完成，不释放锁，那么其他进程一直处于休眠状态，当某进程释放锁并且唤醒队列头部的进程时，注意此时其他进程并未被唤醒，只有当该被唤醒的进行被系统调度到后才去唤醒下一个进程*）


这里老师给出的解释是会依次唤醒全部阻塞队列，然后有系统调度去决定哪一个进程获取锁，由于给出的代码只是伪代码，所以此处理解为会有其他代码去保证这一行为。


唤醒全部进程的理由：由于不确定优先级，假如唤醒一个线程就去让它得到锁会有额外损失。





## 死锁

定义：相互持有对方所需资源所导致的僵持状态。




# 内存


## 程序的地址转变

![[img/Pasted image 20240819172250.png]]


**逻辑地址/相对地址->真实的物理地址**

一段高级语言的程序通常有编译、运行两个阶段，但无论如何在运行阶段其程序被载入磁盘，例如call 40(这里假设40是main函数的地址)执行程序，但是有一个问题，那就是编译阶段的地址和运行时的地址是否一致？由于在运行阶段程序文件才被真正的载入磁盘，知道真实的物理地址，可以使用cs:ip指向执行，但是编译阶段是不知道运行时的物理地址，这时地址使用逻辑地址/相对地址表示。*将地址转变的操作被称为重定位。*


**物理地址的转变**

除此之外程序载入磁盘后，有时还需要进行移动，例如进程阻塞、调度等操作，会将进程退出，此时为了避免占用内存资源，会让改阻塞进程退出占用内存，然后换其他进程执行，这就意味着交换内存空间，对于本章节来说，意味着真实的物理地址发生了改变。



因此对于程序来说，每次运行都要对地址进行重定位，这种机制被称为地址翻译。
*真实物理地址=base(相对地址)+offset(偏移)*

### 运行时重定位(地址翻译)：MMU，

基地址存储在pcb中，执行指令时会先从pcb中的LDT表中找到基地址，然后计算出真实的物理地址。


### 防止地址越界

![image.png](http://obimage.wenzhuo4657.cn/20241016095226.png)

限长寄存器存放作业所占分区的长度，基址寄存器则存放作业所占分区的起始地址，这两个值确定了一个分区的位置和大小。

　　转换时根据逻辑地址与限长值比较，如果不有超过这个值，表示访问地址合法，再加上基址寄存器中的值就得到了绝对地址了，否则形成“地址越界”中断。达到存储保护的目的。

　　对于共享程序，则硬件提供两组限长寄存器和基址寄存器。访问时对访问区享区和作业区的地址分别进行转换。
参考： https://www.cnblogs.com/hao02171990/p/3292992.html

## MMU（内存管理单元）
MMU是处理器中的一个硬件模块，它负责将程序的虚拟地址转换为物理地址，也就是运行时重定位（地址翻译）。
![image.png](http://obimage.wenzhuo4657.cn/20241016092948.png)



如果处理器启用了MMU，CPU执行单元发出的内存地址将被MMU截获，从CPU到MMU的地址称为虚拟地址（**Virtual Address**，以下简称**VA**），而MMU将这个地址翻译成另一个地址发到CPU芯片的外部地址引脚上，也就是将VA映射成PA，


参考：[MMU内存管理单元 - AlanTu - 博客园 (cnblogs.com)](https://www.cnblogs.com/alantu2018/p/9002309.html)








## 分段载入
在编译时将程序分段。

![[img/Pasted image 20240820123224.png]]


## cpu的寻址

### 地址空间
在早期的计算机结构中，存在一种，cpu内部地址总线16位，内存地址总线长度为20位，因此使用地址加法器（段地址X16+偏移地址），来进行地址总线的提升，使cpu能够完全管理内存地址，但是随着发展，出现了相反的局面，即cpu地址总长长度所能管理的内存空间>真实的地址空间
例如 64位（指cpu内部地址总线位64位）操作系统它可以在64位CPU上运行，并且能够利用64位的内存地址总线来管理**多达256TB**（实际上没有这么多）的物理内存。


### 外部设备的接入


对于cpu而言，它是操控着计算机上的一切，包括外设，例如蓝牙耳机、显示器、打印机等等，这些东西都可以通过无线或者有线的方式来接入操作系统，那么cpu该如何管理它们？

首先我们要明确的是这些外设都会提供一些寄存器，因此cpu管理外设的首要目标就是如何找到这些寄存器。
![[Pasted image 20241106185521.png]]




#### 寻找外设
参考：
[IO端口和IO内存的区别及分别使用的函数接口-阿里云开发者社区](https://developer.aliyun.com/article/296914)
[20150222 IO端口映射和IO内存映射(详解S3C24XX\_GPIO驱动) - Lover雪儿 - 博客园](https://www.cnblogs.com/lihaiyan/p/4297769.html)
##### IO端口/独立编制

给控制器中的每一个寄存器分配一个唯一的I/O端口（I/O port）编号，称为I/O端口地址，然后用专门的I/O指令对端口进行操作。
![[Pasted image 20241106185650.png]]



　　访问IO端口有2种途径：
　　- I/O映射方式（I/O－mapped）：直接使用intb()/outb()之类的函数来读写IO端口
　　- 内存映射（MMIO）：IO设备端口被映射到内存空间，映射后，CPU访问IO端口就如同访问内存一样




##### IO内存/统一编址
基本思路：把所有控制器中的每个寄存器都映射为一个物理内存地址，专门用于I/O操作（功能上），对这些单元的读写操作即为普通的内存访问操作。
端口地址空间与物理内存的地址空间统一编址，前者是后者的一部分，一般位于后者的顶端部分。
![[Pasted image 20241106185804.png]]





访问：将其编入虚拟内存，使用内存地址访问


#### 和外设的通信

*首先要明确是，无论是io端口还是io内存都仅仅是单向通信，使cpu和可以通过某种方式和外设进行通信，但需要注意的是，外设无法主动发送信息到cpu或者说某一段正在执行的程序。*

[操作系统学习笔记（11）——设备管理和I/O控制的方式 - 从未想过的想 - 博客园](https://www.cnblogs.com/taking/p/15674763.html)

##### 循环检测
当我们的程序需要外设时，不断地检测外设地状态来进行下一步指令。（这当然是耗费大量资源地方式）

##### 中断驱动
- 仅当操作正常或异常结束时才中断CPU。实现了一定程度的并行操作，这叫中断方式。在主机启动外设后，不必查询外设是否就绪，而是继续执行现行程序，对设备是否就绪不加过问。此时主机和外设并行操作。外设准备完毕，将数据传送至设备控制器的寄存器后，外设向主机发出中断请求，主机从设备控制中将数据读入内存指定单元。

- 在中断方式中，外设输入**每个数据**的过程中，无需主机的干预，因而**可使得主机与外设并行工作**。仅当输完一个数据时，才需要主机花费时间中断处理。**中断方式在一定程度上提高了主机和外设的并行程度**，提高计算机系统资源的利用率。

![[Pasted image 20241106200709.png]]
对于中断驱动应该避免生成大量中断，导致cpu繁忙，。以下是常见情况
- 由于部分设备（如键盘、鼠标)被设计为每次只处理一个字，或者较小的数据量，
- 数据通信中通常要求精确度，例如串行传输，每个字节之间可能存在特定的时间间隔。

此外对于中断本身而言，它会使cpu切换当前正在执行的作业来去完成中断程序，这本身就要求中断时间不能过长，否则就会损耗系统的响应速度和实时性。


##### DMA
**DMA是一种无需CPU的参与就可以让外设和系统内存之间进行双向数据传输的硬件机制。**


![[Pasted image 20241106195356.png]]


DMA代替cpu来执行数据传输的工作，并且建立了数据块通道来增加每次中断的通信量。




## 内存分区与分页


可变分区：根据算法进行选择，
![[img/Pasted image 20240820130928.png]]


此处根据老师的讲解，
最佳适配的原则是尽量从适配空间最小的开始分割。
最差适配的原则是从适配空间最大的开始分割。

### 分页
引入分页的目的是：解决内存分区导致的内存效率问题（例如，内存空间总空闲足够但不连续，简单来说就是内存碎片过多，其总量无法被忽视）。
![[img/Pasted image 20240820132445.png]]


将内存划分为页，针对每个段的内存申请取整分配给足够的页，此时解决内存碎片的问题变为：如果使用这些分散的页？


使用页表，并且根据cr3指向当前页表的地址，然后可以根据该页表中存储页的位置计算出真实的物理地址，分段时是根据段地址、偏移地址然后进行地址翻译，此时根据页地址进行地址翻译，其核心操作变未，只是使用的表改变了。


![[img/Pasted image 20240820134032.png]]


这里需要注意，页框号是在未分配的时候就已经规定好的了，与页号不同，经页表得到的地址还需要经过gdt表转换。




### 多级页表和快表

分页的问题：页越小内存利用率越高，但同时页表也就越大。
![[img/Pasted image 20240820135300.png]]


**编译时程序会分散使用地址空间，意味着大部分表项为空，会使表项进一步增多。但是由于在页号连续情况下可以直接将页号当做偏移量进行查找页表，所以不能通过直接删除无用表项减小页表的大小。**



此时问题变为，在页号连续的情况下，尽可能缩小页表的大小。*但这并不意味着不能删除无用项，只是需要保证页号的连续。*


多级页表中地址翻译为：高10位是页目录号，次高10位是页号，低12位是页内偏移。

这里的问题是如何根据页目录号找到对应的章节？由于不同章节的大小的不同，不能简单的偏移寻址。
对于多级页表来说，是使用页目录号管理页表，找到页目录号即找到对应的页表地址。



### 快表
多级分表解决了空间上的效率，但是时间上，也就是访问次数增加了。




![[img/Pasted image 20240820190721.png]]


使用tlb快表，记忆逻辑页号和页框号的对应关系，简单点说就是页号的高速缓存表。




![[img/Pasted image 20240820191049.png]]










![[img/Pasted image 20240820191112.png]]






## 段页结合的实际内存管理

根据前面所讲，似乎段的设置已经过时了，应该使用页，但请注意，段提出的本意并非解决内存利用率，而是程序分段的问题。

因此提出第三种的解决方法为，使用虚拟内存，该虚拟内存为==每个进程==，独立存在的，也就是说不会多个进程共享一个虚拟内存，而其本质上仅仅是中转站，类似与未翻译的原地址，仍需要页表进行地址翻译。（*页直接指向真实的物理地址*）




*虽说进程独占虚拟内存，但这并不意味着其可以直接分配虚拟内存，进程内部仍有线程颗粒，对此，解决办法依旧为分区表，此时问题绕回了分段时产生大量内存碎片，但由于独占虚拟内存，且足够大，所以内存碎片可以的损耗可以忍受，或者说，一般不会需要使用到全部的虚拟内存。*


### fork源码分析

![[img/Pasted image 20240826205534.png]]

上图中两个函数为liunx0.11的两个函数，作用为分配虚拟内存，建立段表，需要注意，此时的linux并未实现多用户，此时仍未实现进程独占的虚拟内存，上图分配内存的方式是为每个进程分配一块虚拟内存。

早期版本的虚拟内存，仅仅为了兼容段分配和页分配。

![[img/Pasted image 20240826210035.png]]


*且注意对于fork的子进程，需要和父进程共享内存空间，因此，无论是早期的虚拟内存还是现在的虚拟内存，其逻辑地址最终指向的物理空间都是相同，这里体现为页表相同。*

copy_page_tables就是用于完成页表复制的。

![[img/Pasted image 20240826211050.png]]





## 内存换入换出

要想实现虚拟内存，就必须实现内存换入换出



### 内存换入-请求调页


当虚拟内存可以分配，但是没有实际的物理内存，这种情况被称为缺页。

缺页时，当MMU（Memory Management Unit，内存管理单元）检测到缺页时，它会触发一个硬件中断，这个中断信号会通知CPU发生了缺页异常。CPU通过特定的硬件机制来识别这个中断信号。
1. **保存上下文**：当缺页发生时，处理器会自动保存当前执行的状态（如寄存器的内容）。
2. **跳转到中断处理程序**：处理器跳转到一个预定义的地址开始执行中断处理程序。
3. **处理缺页**：中断处理程序会查找请求的页面是否存在于磁盘或其他存储介质上，并将其加载到物理内存中。 
4. **更新页表**：中断处理程序会更新页表，确保下一次访问相同的虚拟地址时可以直接找到对应的物理地址。
5. **恢复执行**：中断处理程序完成后，处理器会恢复之前保存的上下文，并重新执行导致缺页异常的指令。



### 内存换出

换出对应换入，即将页释放，空闲出页提供给其他进程使用。


![[img/Pasted image 20240827090117.png]]


LRU算法是对程序调用的局部性的一种认识，但在具体实现中无论使用什么指标判断，最后都发现代价很大，最后工程师给出的解决方案是在硬件层面解决，（这个方式的转变让我想起看过的一篇文章，就是将算法的复杂度降为0，也就是思考是否需要这个算法。）



这种算法被称为clock算法，访问时将r变为1，指针扫描将1变为0，遇到0淘汰该页。
此处存在一个问题，那就是将r变为1的频率（进程访问）和1变为0的频率（缺页）的相对来说的高低。当缺页很少时，两次缺页的时间间隔足够所有进程访问一次，也就是说，所有的r又都变为1，无法淘汰页，又或者当进程访问很少时，缺页指针将所有的r都置为0，此时变成了FIFO。
对于FIFO来说，既然进程访问过少，那么理论上淘汰哪一个都可以；但是当缺页很少时，时间间隔的过长的问题本质是，r记录的历史信息太多，此处给出的解决办法是，另外给出一个扫描指针定时清除R位。

![[img/Pasted image 20240827092040.png]]


![[img/Pasted image 20240827093630.png]]




# 文件视图


计算机使用外设
- 向外设的寄存器或者存储器发出读写指令
- 为了隐蔽复杂细节，使用设备文件进行封装处理
- 中断处理
## IO与显示器


![[img/Pasted image 20240827153322.png]]

![[img/Pasted image 20240827153259.png]]

![[img/Pasted image 20240827153112.png]]


文件视图的作用是提供控制外设的一种方式，通过操作系统提供的统一接口操作，然后可以根据这些设备文件来控制外设，
*操控外设即操作外设的寄存器等，在内存中表示为某些内存单元。*


[OS-李治军-L26-IO与显示器 - HermioneGranger - 博客园 (cnblogs.com)](https://www.cnblogs.com/HermioneBlog/p/13917326.html)
这段源代码真的很懵逼，贴一篇文章。


![[img/Pasted image 20240827160930.png]]



## 键盘

硬件发出中断信号。

![[img/Pasted image 20240827161759.png]]

键盘上每个键都有对应的扫描码，中断处理程序Keyboard_interrrupt从对应端口读取到扫描码然后继续向下执行，代码中表现为，将器读进al寄存器中。


![[img/Pasted image 20240827162150.png]]


调用key_table函数来决定具体执行什么，且注意，此处依旧有缓冲区的存在，并非直接执行。





# 概念


cpu状态分为管态（内核态）和目态（用户态）。

管态-》目态：修改psw关键字。

